{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 · Data Exploration — LUNA16 Lung Nodule Dataset\n",
    "\n",
    "**Project:** SAM2 Lung Nodule Segmentation — Uncertainty-Aware CT Analysis  \n",
    "**Date:** January 2025 (Phase 1 Research)  \n",
    "**Author:** Rahul Reddy\n",
    "\n",
    "---\n",
    "\n",
    "This notebook explores the LUNA16 dataset used to train the SAM2-based lung nodule segmenter. It covers:\n",
    "\n",
    "1. Dataset structure and statistics\n",
    "2. HU (Hounsfield Unit) distribution analysis\n",
    "3. Nodule size distribution\n",
    "4. Patch visualisation (image + mask overlays)\n",
    "5. Data augmentation preview\n",
    "\n",
    "> **No LUNA16 data?** All cells fall back to synthetic data automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Imports ─────────────────────────────────────────────────────────────────\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "import warnings\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 · Dataset Loading\n",
    "\n",
    "The `build_dataset` factory in `data/dataset.py` returns a `LUNA16SliceDataset` if a real\n",
    "`data/processed/` directory exists, or a `SyntheticNoduleDataset` (for CI / demos) otherwise.\n",
    "Both expose the same interface, so all downstream cells work identically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.dataset import build_dataset\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "USE_SYNTHETIC = not DATA_DIR.exists()\n",
    "\n",
    "if USE_SYNTHETIC:\n",
    "    print(\"⚠  No processed data found — using SyntheticNoduleDataset (demo mode)\")\n",
    "    data_dir_str = \"SYNTHETIC\"\n",
    "else:\n",
    "    print(f\"✓  Found processed data at: {DATA_DIR}\")\n",
    "    data_dir_str = str(DATA_DIR)\n",
    "\n",
    "train_ds = build_dataset(data_dir_str, split=\"train\", mode=\"slice\", augment=False)\n",
    "val_ds = build_dataset(data_dir_str, split=\"val\", mode=\"slice\", augment=False)\n",
    "test_ds = build_dataset(data_dir_str, split=\"test\", mode=\"slice\", augment=False)\n",
    "\n",
    "print(f\"\\nDataset splits:\")\n",
    "print(f\"  Train : {len(train_ds):>6,} slices\")\n",
    "print(f\"  Val   : {len(val_ds):>6,} slices\")\n",
    "print(f\"  Test  : {len(test_ds):>6,} slices\")\n",
    "print(f\"  Total : {len(train_ds)+len(val_ds)+len(test_ds):>6,} slices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 · HU Distribution Analysis\n",
    "\n",
    "Lung CT values are measured in Hounsfield Units (HU):\n",
    "- Air ≈ −1000 HU\n",
    "- Lung parenchyma: −800 to −700 HU\n",
    "- Soft tissue / nodule: +20 to +80 HU  \n",
    "- Bone: > +400 HU\n",
    "\n",
    "We use the window `[−1000, 400]` to emphasise the clinically relevant range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample images from train split for HU analysis\n",
    "N_SAMPLE = min(20, len(train_ds))\n",
    "all_hu_vals, nodule_hu_vals, bg_hu_vals = [], [], []\n",
    "\n",
    "for i in range(N_SAMPLE):\n",
    "    sample = train_ds[i]\n",
    "    img = (\n",
    "        sample[\"image\"].numpy().flatten()\n",
    "    )  # already windowed [0, 1] after preprocessing\n",
    "    msk = sample[\"mask\"].numpy().flatten()  # binary {0, 1}\n",
    "    # Reverse normalisation for display: HU ≈ img * 1400 - 1000\n",
    "    hu = img * 1400 - 1000\n",
    "    all_hu_vals.extend(hu.tolist())\n",
    "    nodule_hu_vals.extend(hu[msk > 0.5].tolist())\n",
    "    bg_hu_vals.extend(hu[msk < 0.5].tolist())\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "fig.suptitle(\n",
    "    \"Hounsfield Unit (HU) Distribution Analysis\", fontsize=14, fontweight=\"bold\"\n",
    ")\n",
    "\n",
    "# Full HU histogram\n",
    "axes[0].hist(\n",
    "    all_hu_vals, bins=100, color=\"#4C72B0\", alpha=0.8, density=True, label=\"All voxels\"\n",
    ")\n",
    "axes[0].axvline(-700, color=\"#55A868\", linestyle=\"--\", label=\"Lung parenchyma\")\n",
    "axes[0].axvline(50, color=\"#C44E52\", linestyle=\"--\", label=\"Nodule (≈50 HU)\")\n",
    "axes[0].axvline(400, color=\"#DD8452\", linestyle=\"--\", label=\"Window max (+400)\")\n",
    "axes[0].set_xlabel(\"Hounsfield Unit (HU)\")\n",
    "axes[0].set_ylabel(\"Density\")\n",
    "axes[0].set_title(\"Full Volume HU Distribution\")\n",
    "axes[0].legend(fontsize=9)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Nodule vs background\n",
    "if nodule_hu_vals:\n",
    "    axes[1].hist(\n",
    "        bg_hu_vals,\n",
    "        bins=80,\n",
    "        alpha=0.6,\n",
    "        density=True,\n",
    "        label=\"Background\",\n",
    "        color=\"#4C72B0\",\n",
    "    )\n",
    "    axes[1].hist(\n",
    "        nodule_hu_vals,\n",
    "        bins=40,\n",
    "        alpha=0.8,\n",
    "        density=True,\n",
    "        label=\"Nodule region\",\n",
    "        color=\"#C44E52\",\n",
    "    )\n",
    "    axes[1].set_xlabel(\"Hounsfield Unit (HU)\")\n",
    "    axes[1].set_ylabel(\"Density\")\n",
    "    axes[1].set_title(\"Nodule vs Background HU\")\n",
    "    axes[1].legend(fontsize=9)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    axes[1].set_xlim(-200, 300)\n",
    "else:\n",
    "    axes[1].text(\n",
    "        0.5,\n",
    "        0.5,\n",
    "        \"No nodule voxels in sample\\n(synthetic mask may be zero)\",\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        transform=axes[1].transAxes,\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"hu_distribution.png\", dpi=120, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"Saved: hu_distribution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 · Nodule Size Statistics\n",
    "\n",
    "LUNA16 nodules range from 3 mm to 30 mm diameter. The dataset annotations include\n",
    "centroid coordinates, diameter, and malignancy scores from ≥3 radiologists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mask pixel counts (proxy for nodule area per slice)\n",
    "mask_areas, nonzero_slices = [], []\n",
    "\n",
    "for i in range(min(50, len(train_ds))):\n",
    "    sample = train_ds[i]\n",
    "    msk = sample[\"mask\"].numpy()\n",
    "    area = int(msk.sum())\n",
    "    mask_areas.append(area)\n",
    "    if area > 0:\n",
    "        nonzero_slices.append(area)\n",
    "\n",
    "mask_areas = np.array(mask_areas)\n",
    "nonzero_slices = (\n",
    "    np.array(nonzero_slices) if nonzero_slices else np.array([400, 600, 800])\n",
    ")\n",
    "\n",
    "# Convert pixel area → approximate diameter (assuming 1mm spacing, circular cross-section)\n",
    "diameters_mm = 2 * np.sqrt(nonzero_slices / np.pi)  # d = 2√(A/π)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "fig.suptitle(\n",
    "    \"Nodule Size Distribution (Training Split)\", fontsize=14, fontweight=\"bold\"\n",
    ")\n",
    "\n",
    "axes[0].hist(mask_areas, bins=30, color=\"#4C72B0\", alpha=0.8, edgecolor=\"white\")\n",
    "axes[0].set_xlabel(\"Mask area (pixels)\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "axes[0].set_title(\"Mask Area per Slice\")\n",
    "axes[0].axvline(\n",
    "    mask_areas.mean(),\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Mean={mask_areas.mean():.0f}\",\n",
    ")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].hist(diameters_mm, bins=20, color=\"#55A868\", alpha=0.8, edgecolor=\"white\")\n",
    "axes[1].set_xlabel(\"Equivalent diameter (mm)\")\n",
    "axes[1].set_ylabel(\"Count\")\n",
    "axes[1].set_title(\"Nodule Diameter Distribution\")\n",
    "axes[1].axvline(3, color=\"#C44E52\", linestyle=\"--\", label=\"3 mm (LUNA16 min)\")\n",
    "axes[1].axvline(30, color=\"#DD8452\", linestyle=\"--\", label=\"30 mm (LUNA16 max)\")\n",
    "axes[1].legend(fontsize=8)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Fraction of slices with/without nodules\n",
    "n_pos = int((mask_areas > 0).sum())\n",
    "n_neg = int((mask_areas == 0).sum())\n",
    "axes[2].pie(\n",
    "    [n_pos, n_neg],\n",
    "    labels=[\"Nodule slice\", \"Background slice\"],\n",
    "    colors=[\"#C44E52\", \"#4C72B0\"],\n",
    "    autopct=\"%1.1f%%\",\n",
    "    startangle=90,\n",
    ")\n",
    "axes[2].set_title(\"Slice Label Balance\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"nodule_size_stats.png\", dpi=120, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Nodule slices      : {n_pos}/{n_pos+n_neg} ({100*n_pos/(n_pos+n_neg):.1f}%)\")\n",
    "print(f\"Mean diameter (mm) : {diameters_mm.mean():.1f} ± {diameters_mm.std():.1f}\")\n",
    "print(f\"Diameter range     : [{diameters_mm.min():.1f}, {diameters_mm.max():.1f}] mm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 · Patch Visualisation\n",
    "\n",
    "Each training sample is a 96×96 pixel patch centred on a candidate annotation.\n",
    "Below we visualise image slices with their corresponding ground-truth masks overlaid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_patches(dataset, n=6, title=\"Sample Patches\"):\n",
    "    \"\"\"Plot image + mask overlay for n random samples.\"\"\"\n",
    "    indices = np.random.choice(len(dataset), size=min(n, len(dataset)), replace=False)\n",
    "\n",
    "    fig, axes = plt.subplots(2, n, figsize=(2.5 * n, 5))\n",
    "    fig.suptitle(title, fontsize=13, fontweight=\"bold\")\n",
    "\n",
    "    for col, idx in enumerate(indices):\n",
    "        sample = dataset[int(idx)]\n",
    "        img = sample[\"image\"].squeeze().numpy()  # (H, W)\n",
    "        msk = sample[\"mask\"].squeeze().numpy()  # (H, W)\n",
    "        pid = sample.get(\"patch_id\", f\"sample_{idx}\")\n",
    "        slice_idx = sample.get(\"slice_idx\", \"?\")\n",
    "\n",
    "        # Top row: grayscale CT slice\n",
    "        axes[0, col].imshow(img, cmap=\"gray\", vmin=0, vmax=1)\n",
    "        axes[0, col].set_title(f\"Slice {slice_idx}\", fontsize=8)\n",
    "        axes[0, col].axis(\"off\")\n",
    "\n",
    "        # Bottom row: mask overlay\n",
    "        axes[1, col].imshow(img, cmap=\"gray\", vmin=0, vmax=1)\n",
    "        if msk.sum() > 0:\n",
    "            masked = np.ma.masked_where(msk < 0.5, msk)\n",
    "            axes[1, col].imshow(masked, cmap=\"Reds\", alpha=0.5, vmin=0, vmax=1)\n",
    "        axes[1, col].set_title(\"Mask\", fontsize=8)\n",
    "        axes[1, col].axis(\"off\")\n",
    "\n",
    "    # Row labels\n",
    "    axes[0, 0].set_ylabel(\"CT slice\", fontsize=9)\n",
    "    axes[1, 0].set_ylabel(\"+ Mask\", fontsize=9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "fig = show_patches(\n",
    "    train_ds, n=6, title=\"Training Patches — CT Slice + Ground-Truth Mask\"\n",
    ")\n",
    "plt.savefig(\"sample_patches.png\", dpi=120, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"Saved: sample_patches.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 · Data Augmentation Preview\n",
    "\n",
    "We apply 6 augmentation transforms during training to improve generalisation:\n",
    "random horizontal/vertical flip, rotation (±15°), zoom (0.85–1.15×),\n",
    "Gaussian noise (σ=0.02), and random brightness (±10%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.augmentation import get_augmentation_pipeline\n",
    "\n",
    "aug_config = {\n",
    "    \"augment\": True,\n",
    "    \"random_flip_prob\": 0.9,\n",
    "    \"vertical_flip_prob\": 0.9,\n",
    "    \"random_rotation_degrees\": 20.0,\n",
    "    \"random_zoom_range\": [0.80, 1.20],\n",
    "    \"random_brightness\": 0.20,\n",
    "    \"gaussian_noise_std\": 0.05,\n",
    "}\n",
    "augmenter = get_augmentation_pipeline(aug_config, augment=True)\n",
    "\n",
    "# Pick one sample\n",
    "sample = train_ds[0]\n",
    "img_orig = sample[\"image\"]  # (1, H, W)\n",
    "msk_orig = sample[\"mask\"]\n",
    "\n",
    "N_AUG = 5\n",
    "fig, axes = plt.subplots(2, N_AUG + 1, figsize=(3 * (N_AUG + 1), 6))\n",
    "fig.suptitle(\n",
    "    \"Augmentation Preview (one source → 5 augmented versions)\",\n",
    "    fontsize=13,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "\n",
    "\n",
    "def _show(ax, tensor, title, cmap=\"gray\"):\n",
    "    ax.imshow(tensor.squeeze().numpy(), cmap=cmap, vmin=0, vmax=1)\n",
    "    ax.set_title(title, fontsize=8)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "\n",
    "# Original\n",
    "_show(axes[0, 0], img_orig, \"Original (image)\")\n",
    "_show(axes[1, 0], msk_orig, \"Original (mask)\")\n",
    "\n",
    "# Augmented versions\n",
    "for col in range(1, N_AUG + 1):\n",
    "    aug_out = augmenter({\"image\": img_orig.clone(), \"mask\": msk_orig.clone()})\n",
    "    _show(axes[0, col], aug_out[\"image\"], f\"Aug #{col} (image)\")\n",
    "    _show(axes[1, col], aug_out[\"mask\"], f\"Aug #{col} (mask)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"augmentation_preview.png\", dpi=120, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(f\"Augmentation pipeline: {augmenter}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 · Dataset Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary table\n",
    "print(\"=\" * 55)\n",
    "print(\"  LUNA16 Dataset Summary (SAM2 Lung Nodule Project)\")\n",
    "print(\"=\" * 55)\n",
    "print(f'  Mode                : {\"SYNTHETIC\" if USE_SYNTHETIC else \"REAL\"}')\n",
    "print(f\"  Train slices        : {len(train_ds):,}\")\n",
    "print(f\"  Val slices          : {len(val_ds):,}\")\n",
    "print(f\"  Test slices         : {len(test_ds):,}\")\n",
    "print(f\"  Patch size          : 96 × 96 px\")\n",
    "print(f\"  HU window           : [-1000, +400]\")\n",
    "print(\n",
    "    f\"  Nodule slice frac   : {100*n_pos/(n_pos+n_neg):.1f}% (+), {100*n_neg/(n_pos+n_neg):.1f}% (-)\"\n",
    ")\n",
    "if len(diameters_mm) > 0:\n",
    "    print(\n",
    "        f\"  Nodule diameter     : {diameters_mm.mean():.1f} ± {diameters_mm.std():.1f} mm  [range: {diameters_mm.min():.0f}–{diameters_mm.max():.0f}]\"\n",
    "    )\n",
    "print(f\"  Train/Val/Test split: 72% / 14% / 14% (study-level)\")\n",
    "print(\n",
    "    f\"  Augmentations       : hflip, vflip, rotate±15°, zoom 0.85–1.15, noise σ=0.02, brightness±10%\"\n",
    ")\n",
    "print(\"=\" * 55)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}