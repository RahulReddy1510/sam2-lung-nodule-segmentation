================================================================================
MASTER BUILD PROMPT — SAM2 LUNG NODULE SEGMENTATION PROJECT
Repository: sam2-lung-nodule-segmentation
Author context: Rahul Reddy Koulury (NYU MIDSAI applicant)
Simulated timeline: January 2025 – June 2025 (6 months)
================================================================================

You are an expert ML engineer and research software developer. Your task is to
build a COMPLETE, PRODUCTION-QUALITY, FULLY RUNNABLE GitHub research repository
that represents 6 months of serious graduate-level research work. Every single
file must be real, complete, functional code — not stubs, not pseudocode, not
"TODO: implement this". The repo must be indistinguishable from actual research
code that a strong CS master's/PhD applicant would produce.


The project MUST match ALL of the following claims from the applicant's CV:
  - Fine-tuned SAM2 on LUNA16 CT dataset
  - Achieved 94.3% Dice score
  - Implemented slice-level temporal consistency constraint
  - Monte Carlo Dropout for uncertainty estimation
  - Validated on 150 clinical studies, 91% radiologist agreement (Cohen's κ=0.83)
  - Deployed as a 3D Slicer plugin for clinical use

================================================================================
SECTION 1: WHAT TO BUILD — COMPLETE FILE LIST
================================================================================

Build EVERY file listed below. Each file must be complete and runnable.

sam2-lung-nodule-segmentation/
│
├── README.md                              [CRITICAL — reviewers read this first]
├── LICENSE                                [MIT]
├── requirements.txt                       [pinned versions]
├── setup.py                               [installable package]
├── .gitignore
├── CHANGELOG.md                           [6-month version history]
│
├── data/
│   ├── README.md                          [dataset download instructions]
│   ├── luna16_preprocessing.py            [FULL pipeline]
│   ├── dataset.py                         [PyTorch Dataset class]
│   └── augmentation.py                    [all augmentation transforms]
│
├── models/
│   ├── __init__.py
│   ├── sam2_finetune.py                   [SAM2 adaptation]
│   ├── mc_dropout.py                      [MC Dropout wrapper + inference]
│   ├── temporal_consistency.py            [TC loss + combined loss]
│   └── registry.py                        [model factory / registry]
│
├── training/
│   ├── train.py                           [full training loop]
│   ├── config.yaml                        [all hyperparameters]
│   └── lr_scheduler.py                   [custom warmup + cosine]
│
├── evaluation/
│   ├── evaluate.py                        [full test-set eval runner]
│   ├── dice_metric.py                     [Dice, IoU, HD95, sensitivity]
│   ├── uncertainty_calibration.py         [ECE, reliability diagram]
│   └── radiologist_agreement.py           [Cohen's Kappa + plots]
│
├── slicer_plugin/
│   ├── README.md                          [installation + usage]
│   ├── LungNoduleSeg.py                   [Slicer extension — full]
│   └── Resources/
│       └── UI/
│           └── LungNoduleSeg.ui           [Qt XML UI definition]
│
├── notebooks/
│   ├── 01_data_exploration.ipynb          [LUNA16 EDA + preprocessing viz]
│   ├── 02_model_development.ipynb         [architecture ablations]
│   ├── 03_uncertainty_visualization.ipynb [heatmap analysis — MAIN DEMO]
│   └── 04_clinical_validation.ipynb       [radiologist agreement analysis]
│
├── tests/
│   ├── __init__.py
│   ├── test_preprocessing.py              [unit tests for data pipeline]
│   ├── test_model.py                      [unit tests for model + loss]
│   ├── test_metrics.py                    [unit tests for evaluation metrics]
│   └── test_mc_dropout.py                 [unit tests for uncertainty]
│
├── scripts/
│   ├── download_luna16.sh                 [data download helper]
│   ├── run_training.sh                    [training launch script]
│   ├── run_evaluation.sh                  [evaluation launch script]
│   └── run_ablation.sh                    [ablation study launcher]
│
├── configs/
│   ├── base.yaml                          [base config]
│   ├── ablation_no_tc.yaml               [ablation: no temporal loss]
│   ├── ablation_tc_dice.yaml             [ablation: dice temporal]
│   └── ablation_frozen.yaml              [ablation: frozen encoder]
│
├── results/
│   ├── ablation_results.csv              [all ablation numbers]
│   └── README.md                          [how to reproduce results]
│
└── assets/
    ├── banner.png                         [create a description for this]
    └── architecture.png                   [create a description for this]

================================================================================
SECTION 2: README.md REQUIREMENTS (READ CAREFULLY)
================================================================================

The README is the most important file. It will be read in the first 60 seconds.
Build it to communicate research depth immediately. It MUST contain:

2.1 HEADER SECTION
-------------------
- Project title with a one-line hook
- Badges: Python 3.10+ | PyTorch 2.1 | License: MIT | Dice: 94.3% |
  Radiologist Agreement: 91% | Platform: 3D Slicer
- A 2-3 sentence abstract that reads like a paper abstract, not a tutorial

2.2 THE MOTIVATING QUOTE (verbatim, this is the hook)
------------------------------------------------------
Include this exact quote in a blockquote at the top:
> "This tells me where to look twice. That's what I actually need."
> — Radiologist feedback during clinical validation, January 2025

Then 1-2 sentences explaining why this quote reframes the entire project from
an accuracy problem to a trust/communication problem.

2.3 KEY RESULTS TABLE
---------------------
Must show all of these with these exact values:

| Metric                      | Value         |
|-----------------------------|---------------|
| Dice Score (LUNA16 test)    | 94.3%         |
| IoU                         | 89.1%         |
| Hausdorff Distance (HD95)   | 2.3 mm        |
| Sensitivity                 | 93.7%         |
| Specificity                 | 98.1%         |
| Expected Calibration Error  | 0.042         |
| Radiologist Agreement (κ)   | 0.83          |
| Case-level Agreement        | 91% (n=150)   |
| Inference Time (per volume) | ~3.4s (A100)  |

2.4 ABLATION STUDY TABLE (proves the design choices)
----------------------------------------------------
| Model Variant                            | Dice  | ECE   |
|------------------------------------------|-------|-------|
| SAM2 baseline (zero-shot, no finetune)   | 71.2% | 0.210 |
| + Fine-tuning (no temporal loss)         | 91.8% | 0.180 |
| + Temporal consistency (L2 constraint)   | 93.5% | 0.160 |
| + MC Dropout (full model, T=25)          | 94.3% | 0.042 |

2.5 ARCHITECTURE DIAGRAM (ASCII art — must be included)
-------------------------------------------------------
Show the full pipeline in ASCII:
CT Volume → Preprocessing → SAM2 Encoder → Mask Decoder → Segmentation + Uncertainty

Include the temporal consistency constraint visual showing slices t, t+1, t+2
with the L_temporal arrow between them.

2.6 METHODOLOGY SECTION (3-4 paragraphs, paper-style prose)
-----------------------------------------------------------
Paragraph 1: Why SAM2 for CT? The domain gap challenge, how we adapted it.
Paragraph 2: Temporal consistency — the problem with slice-independent prediction,
             the mathematical formulation of L_temporal.
Paragraph 3: Monte Carlo Dropout — why uncertainty matters more than accuracy
             in clinical settings, the radiologist's perspective.
Paragraph 4: Clinical validation methodology — how 150 studies were reviewed,
             how Cohen's Kappa was computed.

2.7 INSTALLATION & QUICKSTART
------------------------------
- conda env setup
- pip install
- SAM2 install from GitHub
- One-command data preprocessing
- One-command training
- One-command evaluation

2.8 PROJECT TIMELINE TABLE (shows 6 months of work)
---------------------------------------------------
| Month | Milestone                                    | Key Output              |
|-------|----------------------------------------------|-------------------------|
| Jan   | Literature review + LUNA16 pipeline          | 71.2% baseline Dice     |
| Feb   | SAM2 adaptation + encoder fine-tuning         | 91.8% Dice              |
| Mar   | Temporal consistency loss integration         | 93.5% Dice              |
| Apr   | MC Dropout + calibration analysis             | 94.3% Dice, ECE 0.042   |
| May   | Clinical validation (150 studies)             | κ=0.83, 91% agreement   |
| Jun   | 3D Slicer deployment + documentation          | Plugin released         |

2.9 CITATION SECTION
---------------------
BibTeX entry for the work.

2.10 ACKNOWLEDGEMENTS
---------------------
Mention LUNA16, Meta SAM2, MONAI, 3D Slicer, Manipal Academy.

================================================================================
SECTION 3: DATA PIPELINE REQUIREMENTS (data/)
================================================================================

3.1 luna16_preprocessing.py
---------------------------
Must implement ALL of the following as real, working code:

- load_mhd_volume(path) → returns (volume_np, spacing, origin)
  Uses SimpleITK. Returns numpy float32 (Z, Y, X), spacing in mm.

- resample_volume(sitk_img, target_spacing=(1.0,1.0,1.0)) → sitk.Image
  Resamples using sitkLinear interpolation.
  New size = round(orig_size * orig_spacing / target_spacing).

- apply_hu_window(volume, hu_min=-1000, hu_max=400) → np.ndarray
  Clips to [hu_min, hu_max], normalizes to [0,1]. Returns float32.

- world_to_voxel(world_coord, origin, spacing) → voxel_idx
  Handles the coordinate transform correctly.

- create_nodule_mask(volume_shape, center_voxel, radius_mm, spacing) → mask
  Spherical binary mask. Uses bounding box optimization to avoid iterating
  full volume. Returns uint8.

- extract_patch(volume, mask, center, patch_size=(96,96,96)) → (vol_patch, mask_patch)
  Zero-pads at boundaries. Returns both image and mask crops.

- get_train_val_test_splits(uids, train=0.72, val=0.14, seed=42) → dict
  Returns {"train": [...], "val": [...], "test": [...]}

- process_dataset(input_dir, output_dir, annotations_csv, ...) → None
  Main orchestration function. Logs progress with tqdm.
  Saves *_image.npy and *_mask.npy pairs.

All functions must have complete docstrings with Parameters, Returns, Notes.
CLI using argparse at the bottom.

3.2 dataset.py
--------------
Implement a PyTorch Dataset class LUNA16SliceDataset that:
- Loads .npy patches from disk
- Serves 2D axial slices ordered by z-index
- Tracks slice_idx (int tensor) for temporal loss
- Tracks patch_id (string) for traceability
- Has a __len__ and __getitem__ that returns a dict:
  {"image": Tensor(1,H,W), "mask": Tensor(1,H,W),
   "slice_idx": Tensor(int), "patch_id": str}
- Has an augment=True/False flag

Also implement LUNA16VolumeDataset for volume-level inference:
- Returns full 3D volumes for inference mode
- Used by the 3D Slicer plugin

3.3 augmentation.py
-------------------
Implement an augmentation pipeline using torchvision or albumentations:
- RandomHorizontalFlip(p=0.5)
- RandomVerticalFlip(p=0.3)
- GaussianNoise(std_range=(0, 0.02))
- RandomBrightness(range=(-0.1, 0.1))
- RandomZoom(range=(0.85, 1.15))
- RandomRotation(degrees=15)
Must be composable. Must include a get_augmentation_pipeline(config) factory.

================================================================================
SECTION 4: MODEL REQUIREMENTS (models/)
================================================================================

4.1 sam2_finetune.py — THIS IS THE CORE FILE, MAKE IT EXCELLENT
----------------------------------------------------------------
The file must implement the following classes with complete, working code:

CLASS: SinusoidalPosEmbed(nn.Module)
- 2D sinusoidal positional encoding
- forward(x: Tensor) → Tensor, adds PE to feature map

CLASS: DropoutMultiheadAttention(nn.MultiheadAttention)
- Subclasses nn.MultiheadAttention
- Adds an extra attn_dropout applied to attention output
- This dropout REMAINS ACTIVE at inference for MC Dropout
- Has attn_dropout_prob parameter

CLASS: LightweightMaskDecoder(nn.Module)
- __init__(embed_dim=256, num_heads=8, mlp_ratio=4.0,
           attn_dropout=0.1, proj_dropout=0.1, num_output_masks=1)
- self.prompt_token = nn.Parameter(torch.randn(1, 1, embed_dim))
  (Replaces SAM2's interactive prompts with a learnable "nodule" token)
- Cross-attention: prompt queries image features (DropoutMultiheadAttention)
- LayerNorm + FFN on prompt
- Upsampling head: ConvTranspose2d × 2 (4× total upscale) → final logits
- forward(image_features: Tensor) → logits: Tensor
- Include return_features=True option for feature visualization

CLASS: FallbackEncoder(nn.Module)
- Simple UNet-style CNN encoder producing (B, embed_dim, H/4, W/4) features
- Used when SAM2 is not installed
- 3 blocks: (in→64→64→pool), (64→128→128→pool), (128→embed_dim→embed_dim)

CLASS: SAM2LungSegmentor(nn.Module)
Main model class:
- __init__(sam2_checkpoint=None, sam2_config=None, embed_dim=256,
           num_heads=8, attn_dropout=0.1, proj_dropout=0.1,
           encoder_frozen=True, in_channels=1)
- self.channel_adapter = nn.Conv2d(1, 3, kernel_size=1) [1-ch CT → 3-ch RGB]
- self.encoder = SAM2 image encoder OR FallbackEncoder
- self.pos_embed = SinusoidalPosEmbed(embed_dim)
- self.decoder = LightweightMaskDecoder(...)
- freeze_encoder() and unfreeze_encoder() methods
- forward(x: Tensor) → logits: Tensor
  x is (B, 1, H, W), logits is (B, 1, H, W)
- num_parameters(trainable_only=True) → int
- If SAM2 not installed: warn and use FallbackEncoder, don't crash

FUNCTION: build_model(**kwargs) → SAM2LungSegmentor
Factory function. Prints parameter count on build.

IMPORTANT: The model must have a real __main__ block that runs a forward pass
with dummy data and prints input/output shapes. This is a quick sanity check
that reviewers may try.

4.2 mc_dropout.py
-----------------
Must implement:

FUNCTION: enable_dropout_modules(model: nn.Module) → None
- Sets all Dropout/Dropout2d/etc layers to .train() mode
- Leaves BatchNorm layers in .eval() mode
- This achieves the MC Dropout regime: stochastic at inference

CONTEXT MANAGER: mc_dropout_mode(model)
- model.eval() → enable_dropout_modules() → yield → model.eval()
- Usage: with mc_dropout_mode(model): ...

FUNCTION: mc_predict(model, x, n_samples=25, batch_size=4, sigmoid=True)
          → Tuple[mean_pred: Tensor, uncertainty: Tensor]
- x is (B, C, H, W)
- Stacks x n_samples times, runs through model in batches of mc_batch_size
- Returns mean_pred (B,1,H,W) and uncertainty=variance (B,1,H,W)
- @torch.no_grad() decorator

FUNCTION: mc_predict_volume(model, volume, n_samples=25, ...)
          → Dict[str, Tensor]
- Processes full 3D volume slice-by-slice
- Returns {"mean_seg", "uncertainty", "binary_mask"}

FUNCTION: entropy_from_samples(samples: Tensor) → Tensor
- Predictive entropy H[p̄] = -p̄ log p̄ - (1-p̄) log(1-p̄)

FUNCTION: compute_uncertainty_stats(uncertainty_map, binary_pred, binary_gt=None)
          → Dict[str, float]
- unc_mean, unc_max, unc_std
- unc_in_pred_mean (uncertainty inside predicted region)
- unc_out_pred_mean (uncertainty outside predicted region)
- unc_at_boundary if gt provided

__main__ block: run a demo with dummy data, print shapes and ranges.

4.3 temporal_consistency.py
---------------------------
Must implement:

FUNCTION: l2_consistency(logits_t, logits_t1) → Tensor
- L2 between sigmoid(logits_t) and sigmoid(logits_t1)

FUNCTION: dice_consistency(logits_t, logits_t1) → Tensor
- 1 - DiceCoefficient(sigmoid(t), sigmoid(t+1))

FUNCTION: dice_loss(logits, targets) → Tensor
- Standard soft Dice loss

FUNCTION: focal_bce_loss(logits, targets, alpha=0.75, gamma=2.0) → Tensor
- Focal BCE

CLASS: TemporalConsistencyLoss(nn.Module)
- __init__(lambda_bce=0.5, lambda_tc=0.3, consistency_mode="l2",
           warmup_epochs=5, focal_alpha=0.75, focal_gamma=2.0)
- set_epoch(epoch) method [activates TC loss after warmup]
- forward(logits, targets, slice_indices=None)
  Returns dict: {"total", "dice", "bce", "temporal"} — all tensors
- TC is only computed between TRULY adjacent slices (|idx_t - idx_{t+1}| == 1)
- TC loss weight is lambda_tc only if epoch >= warmup_epochs

CLASS: AblationLossFactory
- get(variant: str) → TemporalConsistencyLoss
- Variants: "baseline", "tc_l2", "tc_dice"

__main__ block: demo showing warmup (TC inactive) vs active epoch.

================================================================================
SECTION 5: TRAINING REQUIREMENTS (training/)
================================================================================

5.1 train.py — COMPLETE TRAINING LOOP
--------------------------------------
Must implement everything as working code:

CLASS: CheckpointManager
- __init__(output_dir, keep_top_k=3, mode="max")
- save(model, optimizer, epoch, metric, config) → str (path)
- Prunes old checkpoints, keeps only top-K by metric
- Saves: {"epoch", "metric", "state_dict", "optimizer", "config"}

FUNCTION: build_scheduler(optimizer, cfg, steps_per_epoch)
- Linear warmup for warmup_epochs * steps_per_epoch steps
- Then CosineAnnealingLR
- Use SequentialLR

FUNCTION: train_epoch(model, loader, optimizer, criterion, scaler, scheduler,
                      device, cfg, writer, epoch, global_step)
          → Tuple[dict, int]
- Mixed precision via torch.cuda.amp autocast + GradScaler
- Gradient accumulation (accumulate_grad_batches from config)
- Gradient clipping (gradient_clip from config)
- tqdm progress bar with loss, dice, lr in postfix
- TensorBoard scalar logging every 50 steps
- Returns epoch metrics dict and updated global_step

FUNCTION: validate_epoch(model, loader, criterion, device, cfg, writer, epoch,
                         log_images=False)
          → dict
- Uses mc_dropout_mode for inference
- Computes per-sample: Dice, IoU, HD95
- Optional: logs 4-panel grid (CT / GT / pred / uncertainty) to TensorBoard
- Returns {"val_loss", "val_dice", "val_iou", "val_hd95", "val_dice_std"}

FUNCTION: main(cfg_path, data_dir=None, resume=None)
- Load config.yaml
- Set all seeds (random, numpy, torch, cuda)
- Build train and val LUNA16SliceDatasets + DataLoaders
- Build model via build_model()
- Build AdamW optimizer
- Build scheduler via build_scheduler()
- Build TemporalConsistencyLoss
- Build GradScaler
- Build CheckpointManager
- Build SummaryWriter (TensorBoard)
- Encoder freeze/unfreeze schedule: freeze for first encoder_frozen_epochs,
  then rebuild optimizer with encoder params at lr*0.1
- Main for loop: train_epoch → validate_epoch → checkpoint → log
- Print "Training complete. Best Val Dice: X.XXXX" at end

argparse CLI with --config, --data_dir, --resume

5.2 config.yaml
---------------
Complete YAML with ALL of these sections and values:

model:
  sam2_checkpoint: null
  sam2_config: null
  embed_dim: 256
  num_heads: 8
  attn_dropout: 0.10
  proj_dropout: 0.10
  encoder_frozen_epochs: 5

data:
  data_dir: "/data/LUNA16/preprocessed"
  patch_size: [96, 96, 96]
  slice_size: [512, 512]
  hu_min: -1000
  hu_max: 400
  min_nodule_diameter_mm: 3.0
  num_workers: 8
  pin_memory: true
  augmentation:
    random_flip_prob: 0.5
    random_rotation_degrees: 15
    random_zoom_range: [0.85, 1.15]
    gaussian_noise_std: 0.02
    random_brightness: 0.1

training:
  epochs: 60
  batch_size: 8
  accumulate_grad_batches: 4
  optimizer:
    name: "AdamW"
    lr: 2.0e-4
    weight_decay: 1.0e-4
    betas: [0.9, 0.999]
  scheduler:
    name: "CosineAnnealingLR"
    T_max: 60
    eta_min: 1.0e-6
    warmup_epochs: 3
  loss:
    lambda_bce: 0.5
    lambda_tc: 0.3
    consistency_mode: "l2"
    tc_warmup_epochs: 5
    focal_alpha: 0.75
    focal_gamma: 2.0
  mixed_precision: true
  gradient_clip: 1.0
  seed: 42

evaluation:
  val_every_n_epochs: 1
  mc_samples: 25
  mc_batch_size: 5
  threshold: 0.5
  metrics: [dice, iou, hausdorff95, sensitivity, specificity]
  calibration:
    n_bins: 15
    ece_target: 0.05

checkpointing:
  output_dir: "checkpoints/"
  save_every_n_epochs: 5
  keep_top_k: 3
  monitor_metric: "val_dice"
  mode: "max"

logging:
  tensorboard: true
  log_dir: "runs/"
  log_images_every_n_epochs: 5
  log_uncertainty_stats: true

ablations:
  - name: "baseline_no_tc"
    lambda_tc: 0.0
  - name: "tc_dice_consistency"
    consistency_mode: "dice"
    lambda_tc: 0.3
  - name: "higher_mc_dropout"
    attn_dropout: 0.20
    proj_dropout: 0.20
  - name: "frozen_encoder_full"
    encoder_frozen_epochs: 60

================================================================================
SECTION 6: EVALUATION REQUIREMENTS (evaluation/)
================================================================================

6.1 dice_metric.py
------------------
Implement:
- compute_dice(pred, target, smooth=1e-6) → float [tensor in, scalar out]
- compute_iou(pred, target, smooth=1e-6) → float
- compute_sensitivity(pred_np, target_np) → float [TP / (TP + FN)]
- compute_specificity(pred_np, target_np) → float [TN / (TN + FP)]
- compute_hausdorff95(pred_np, target_np, voxel_spacing=(1,1,1)) → float
  Use scipy.spatial.distance.directed_hausdorff. Returns nan if either mask empty.
- compute_average_surface_distance(pred_np, target_np, ...) → float
- run_evaluation(model, data_dir, device, mc_samples=25, split="test") → dict
  Full test-set evaluation loop with MC Dropout.
  Logs mean ± std for all metrics.
  Returns results dict.

CLI: --checkpoint, --data_dir, --config, --mc_samples, --split, --output (json)

6.2 uncertainty_calibration.py
------------------------------
Implement:
- compute_ece(probs, labels, n_bins=15, return_bins=False) → float [or tuple]
  Bins predicted probabilities, compares confidence vs accuracy per bin.
  ECE = Σ (n_bin/n_total) * |confidence - accuracy|
- compute_mce(probs, labels, n_bins=15) → float [max bin gap]
- compute_brier_score(probs, labels) → float [MSE of probs vs labels]

- plot_reliability_diagram(probs, labels, n_bins=15, title, save_path)
  → matplotlib.Figure
  LEFT subplot: calibration bars + diagonal perfect calibration line
    Color bars by overconfidence (red) vs underconfidence (blue)
    Annotate ECE value with color coding (red if > 0.05, green if ≤ 0.05)
  RIGHT subplot: histogram of predicted confidence distribution
    Vertical line at threshold=0.5

- uncertainty_error_correlation(uncertainty_maps, error_maps, save_path)
  → Dict[str, float]
  Compute Spearman and Pearson correlation between uncertainty and error.
  Compare error rate in high-uncertainty vs low-uncertainty pixels.
  Save hexbin scatter plot if save_path provided.

- run_calibration_analysis(model, data_dir, device, n_bins=15, mc_samples=25,
                           output_dir) → dict
  Full pipeline: inference → collect probs/labels → compute metrics → save plots

__main__ demo with synthetic overconfident model.

6.3 radiologist_agreement.py
-----------------------------
Implement:
- compute_cohens_kappa(radiologist_labels, model_labels, weights=None)
  → Tuple[float, dict]
  Uses sklearn.metrics.cohen_kappa_score
  Returns (kappa, details_dict) where details includes confusion matrix,
  pct_agreement, n_total, TP, TN, FP, FN

- interpret_kappa(kappa: float) → str
  Returns interpretation string per standard ranges

- compute_per_study_agreement(model_masks, rad_masks, dice_threshold=0.5)
  → Dict[str, float]
  Returns mean_dice, pct_agreement, n_agreed, n_total

- analyse_uncertainty_utility(radiologist_feedback: List[Dict]) → Dict[str, float]
  Takes structured feedback dicts with keys:
  uncertainty_helpful, would_rescan_region, found_difficult_case,
  confidence_in_diagnosis
  Returns % helpful, % would_rescan, mean_confidence, etc.

- plot_agreement_analysis(dice_scores, kappa, pct_agreement, save_path)
  → matplotlib.Figure
  3-panel figure:
  LEFT: Dice score histogram with mean line and threshold line
  CENTER: Kappa gauge bar showing where 0.83 falls
  RIGHT: Pie chart of agreed vs disagreed cases

- run_clinical_validation(results_json, output_dir) → dict
  Loads JSON, computes all metrics, generates figure, saves report.

__main__ demo: simulate 150-study validation achieving κ=0.83, 91% agreement.
The demo MUST produce the expected numbers when run.

================================================================================
SECTION 7: 3D SLICER PLUGIN REQUIREMENTS (slicer_plugin/)
================================================================================

7.1 LungNoduleSeg.py
--------------------
Full 3D Slicer scripted module following the ScriptedLoadableModule pattern.

CLASS: LungNoduleSeg(ScriptedLoadableModule)
- Set parent.title, categories, contributors, helpText with the key results

CLASS: LungNoduleSegWidget(ScriptedLoadableModuleWidget, VTKObservationMixin)
UI elements (mapped from .ui file):
- inputVolumeSelector (qMRMLNodeComboBox)
- checkpointPathLineEdit + Browse button
- mcSamplesSlider (5-50, default 25) with value label
- thresholdSlider (0.10-0.90, default 0.50) with value label
- huMinSpinBox (default -1000), huMaxSpinBox (default 400)
- applyButton (disabled until input + checkpoint set)
- statusLabel (shows "Running..." then "Done! Dice≈X.XX")
- outputMaskSelector (qMRMLNodeComboBox for LabelMapVolumeNode)
- uncertaintyVolumeSelector (qMRMLNodeComboBox for ScalarVolumeNode)
- exportDicomButton

Implement all signal connections and onXxx handlers.
_updateButtonState() enables applyButton iff both inputs are set.
_displayUncertaintyOverlay() overlays uncertainty with ColdToHotRainbow colormap
at 50% opacity.

CLASS: LungNoduleSegLogic(ScriptedLoadableModuleLogic)
- _ensure_deps(): pip_install if torch/SimpleITK missing
- _load_model(checkpoint_path): load + cache model, warn if fallback used
- run(input_volume, checkpoint_path, mc_samples, threshold, hu_min, hu_max)
  → dict with mask_node, uncertainty_node, mean_uncertainty
  1. Extract numpy array from Slicer volume
  2. apply_hu_window()
  3. mc_predict_volume() slice-by-slice
  4. Push results back as vtkMRMLLabelMapVolumeNode and vtkMRMLScalarVolumeNode
- export_dicom_seg(mask_node, output_dir): DICOM SEG export

CLASS: LungNoduleSegTest(ScriptedLoadableModuleTest)
- setUp() clears scene
- test_logic_basic(): creates synthetic volume, instantiates logic

7.2 LungNoduleSeg.ui (Qt XML)
------------------------------
Complete Qt Designer XML. All widgets listed in 7.1 must be present with
correct objectNames, types, properties (min/max/value for sliders/spinboxes).
Layout: QVBoxLayout with collapsible sections (ctkCollapsibleButton):
- "Inputs" section
- "Parameters" section
- Apply button + status label
- "Outputs" section
- Export button
- Vertical spacer at bottom

7.3 slicer_plugin/README.md
----------------------------
Include:
- Requirements (3D Slicer ≥ 5.0, Python 3.9+)
- Two installation methods (Manual module path + Extension Manager note)
- Step-by-step usage (4 numbered steps)
- Checkpoint download URL (placeholder releases page URL)
- Checkpoint comparison table (best_model.pth vs baseline)
- Clinical validation summary
- Known limitations section (min nodule size, slice thickness, not for clinical dx)

================================================================================
SECTION 8: JUPYTER NOTEBOOKS REQUIREMENTS (notebooks/)
================================================================================

All notebooks must be complete, with real code cells AND markdown explanation cells.
They must work with synthetic data if the real LUNA16 data is not present.

8.1 01_data_exploration.ipynb
-----------------------------
Cell 1: Setup + imports
Cell 2: Load and display a raw LUNA16 .mhd CT slice (or synthetic)
Cell 3: Show HU distribution before/after windowing (matplotlib histogram)
Cell 4: Show resampling effect (slice before vs after 1mm resampling)
Cell 5: Visualize nodule annotations overlaid on CT
Cell 6: Dataset statistics (nodule size distribution, per-split counts)
Cell 7: Sample augmented versions of the same slice (grid of 8)

8.2 02_model_development.ipynb
-------------------------------
Cell 1: Import model, build with fallback encoder
Cell 2: Print model architecture (torchinfo.summary)
Cell 3: Run forward pass with dummy data, print shapes
Cell 4: Visualize learned prompt token embedding (just show it exists)
Cell 5: Show ablation results from results/ablation_results.csv as styled table
Cell 6: Plot ablation bar chart (Dice and ECE side by side)
Cell 7: Training curve from a saved TensorBoard log or synthetic curve

8.3 03_uncertainty_visualization.ipynb — THE MOST IMPORTANT NOTEBOOK
----------------------------------------------------------------------
This is what a clinical AI reviewer will open. Make it beautiful and compelling.

Cell 1: Imports + config block (CHECKPOINT_PATH, DATA_DIR, MC_SAMPLES)
Cell 2: Custom colormap definition (blue→yellow→red "where to look twice" map)
Cell 3: Load model and checkpoint
Cell 4: Load sample CT patch (fallback to synthetic nodule if no real data)
Cell 5: Run MC Dropout inference (25 passes)
Cell 6: THE MAIN FIGURE — dark background, 4-panel:
         [CT slice | Ground Truth | Prediction | Uncertainty Heatmap]
         Below: [CT + Uncertainty overlay | CT + Prediction contours]
         Title includes Dice score
Cell 7: Temporal consistency strip — 7 adjacent slices showing
        CT / Prediction / Uncertainty in a 3×7 grid
Cell 8: Calibration reliability diagram
Cell 9: Uncertainty-error correlation scatter
Cell 10: Summary results table printed as pandas DataFrame

8.4 04_clinical_validation.ipynb
---------------------------------
Cell 1: Load clinical validation results (or generate synthetic simulation)
Cell 2: Compute Cohen's Kappa with sklearn, print κ=0.83
Cell 3: Plot agreement analysis figure (3-panel)
Cell 4: Uncertainty utility analysis (how often was heatmap helpful)
Cell 5: Case examples — show 3 "easy" cases and 3 "difficult" cases
        Easy: high agreement, low uncertainty. Difficult: radiologist used
        uncertainty heatmap to make final decision.
Cell 6: Clinical validation summary table

================================================================================
SECTION 9: TESTS REQUIREMENTS (tests/)
================================================================================

All tests must be runnable with: pytest tests/ -v
They must PASS with synthetic data (no real LUNA16 needed).

9.1 test_preprocessing.py
--------------------------
- test_apply_hu_window_clips_correctly()
  Input: [-2000, -1000, 0, 400, 1000] → Expected: [0, 0, 0.71, 1, 1] (approx)
- test_apply_hu_window_returns_float32()
- test_hu_window_output_range_is_0_to_1()
- test_create_nodule_mask_sphere_shape()
  Create mask, verify it's spherical (check voxels at exact radius ≈ boundary)
- test_world_to_voxel_correct_transform()
- test_extract_patch_correct_size()
- test_extract_patch_handles_boundary()
  Center near edge → result should still be full patch_size (zero-padded)
- test_get_splits_correct_ratios()
  100 items → ~72 train, ~14 val, ~14 test

9.2 test_model.py
-----------------
- test_model_builds_without_sam2()
  build_model() with no checkpoint → should not raise
- test_model_forward_pass_shape()
  Input (2,1,64,64) → output (2,1,64,64) [or appropriate upsampled size]
- test_model_encoder_freeze()
  freeze_encoder() → all encoder params require_grad=False
- test_model_encoder_unfreeze()
  unfreeze → all params require_grad=True
- test_model_parameter_count_reasonable()
  num_parameters() > 1_000_000 (sanity check)
- test_temporal_loss_zero_when_identical()
  Same logits on both sides → L_temporal should be near 0
- test_temporal_loss_nonzero_when_different()
  Different logits → L_temporal > 0
- test_loss_dict_has_correct_keys()
  criterion.forward() returns dict with "total", "dice", "bce", "temporal"
- test_tc_loss_inactive_during_warmup()
  Set epoch=0 (warmup) → temporal key in losses should be ~0

9.3 test_metrics.py
-------------------
- test_dice_perfect_overlap() → 1.0
- test_dice_zero_overlap() → 0.0 (or near 0 with smooth)
- test_dice_half_overlap() → approximately 0.67
- test_iou_perfect_overlap() → 1.0
- test_iou_zero_overlap() → 0.0
- test_sensitivity_all_tp() → 1.0
- test_specificity_all_tn() → 1.0
- test_ece_perfect_calibration() → near 0.0
  A model that always predicts exactly 0.8 for 80%-correct predictions → ECE≈0
- test_ece_overconfident_model() → ECE > 0.1
- test_cohens_kappa_perfect_agreement() → 1.0
- test_cohens_kappa_chance_agreement() → ≈ 0.0
- test_interpret_kappa_ranges() → correct string for each range

9.4 test_mc_dropout.py
-----------------------
- test_enable_dropout_modules_sets_train_mode()
  After model.eval() + enable_dropout_modules():
  Dropout layers should be in training mode, BatchNorm in eval mode
- test_mc_predict_output_shapes()
  mc_predict(model, x, n_samples=5) → mean_pred and uncertainty both (B,1,H,W)
- test_mc_predict_uncertainty_is_positive()
  variance should be ≥ 0 everywhere
- test_mc_predict_mean_is_probability()
  mean_pred with sigmoid=True → all values in [0,1]
- test_mc_samples_increase_reduces_variance_of_mean()
  With more samples, the mean estimate should be more stable
  (variance of mean_pred over 10 runs should decrease from T=5 to T=50)
- test_mc_dropout_context_manager_restores_state()
  After exiting mc_dropout_mode, model should be back to full eval

================================================================================
SECTION 10: SCRIPTS REQUIREMENTS (scripts/)
================================================================================

10.1 run_training.sh
--------------------
#!/usr/bin/env bash
Complete shell script that:
- Checks Python version ≥ 3.10
- Checks CUDA availability
- Creates output dirs (checkpoints/, runs/)
- Runs: python training/train.py --config training/config.yaml $@
- Handles interrupt (trap)
- Logs start/end time

10.2 run_evaluation.sh
-----------------------
#!/usr/bin/env bash
Runs full test-set evaluation with MC Dropout. Accepts --checkpoint arg.
Also runs calibration analysis and saves results.

10.3 run_ablation.sh
--------------------
#!/usr/bin/env bash
Loops over all 4 ablation configs and trains each.
After all training done, runs evaluation for each and writes
results to results/ablation_results.csv

10.4 download_luna16.sh
-----------------------
#!/usr/bin/env bash
Documents the download process (since URLs require auth).
Includes pip install instructions for gdown/requests.
Shows expected directory structure.
Provides the annotation CSV download (this one IS public via zenodo).

================================================================================
SECTION 11: results/ REQUIREMENTS
================================================================================

11.1 ablation_results.csv
--------------------------
A real CSV with ALL of these exact values (matching the README ablation table):

model_variant,dice,iou,hd95_mm,sensitivity,specificity,ece,notes
sam2_baseline_zeroshot,0.712,0.583,8.4,0.698,0.971,0.210,No finetuning
finetuned_no_temporal,0.918,0.849,3.8,0.912,0.985,0.180,Epoch 60
with_temporal_l2,0.935,0.878,2.9,0.928,0.987,0.160,lambda_tc=0.3
full_model_mc_dropout,0.943,0.891,2.3,0.937,0.981,0.042,T=25 MC samples
full_model_tc_dice,0.931,0.871,3.1,0.924,0.986,0.055,Dice temporal
full_model_high_dropout,0.936,0.880,2.7,0.930,0.982,0.039,p=0.20
frozen_encoder_all,0.894,0.809,4.2,0.887,0.983,0.121,Always frozen

11.2 results/README.md
-----------------------
Explain what each ablation tests and the key takeaways. 3-4 paragraphs.

================================================================================
SECTION 12: CHANGELOG.md — SIMULATING 6 MONTHS OF WORK
================================================================================

This file simulates the project's development history. Write a professional
CHANGELOG in Keep a Changelog format (https://keepachangelog.com).

## [Unreleased]

## [1.0.0] - 2025-06-15
### Added
- 3D Slicer plugin release with full uncertainty heatmap display
- DICOM SEG export functionality
- Clinical validation report for 150 studies

## [0.9.0] - 2025-05-20
### Added
- Clinical validation pipeline (radiologist_agreement.py)
- Cohen's Kappa computation and agreement visualization
- Structured radiologist feedback analysis tools

## [0.8.0] - 2025-05-01
### Added
- MC Dropout inference achieving ECE = 0.042
- uncertainty_calibration.py with reliability diagrams
- uncertainty_error_correlation analysis

## [0.7.0] - 2025-04-10
### Added
- Full test suite (pytest, 28 unit tests)
- GitHub Actions CI workflow
- Ablation runner script

## [0.6.0] - 2025-03-25
### Added
- Temporal consistency loss (L2 mode) — Dice improves 91.8% → 93.5%

## [0.5.0] - 2025-03-05
### Changed
- Unfroze encoder after epoch 5 — end-to-end fine-tuning
- Added focal BCE loss component

## [0.4.0] - 2025-02-20
### Added
- LightweightMaskDecoder with learnable prompt token
- DropoutMultiheadAttention for MC Dropout compatibility
- SAM2 channel adapter (1-channel CT → 3-channel)

## [0.3.0] - 2025-02-05
### Added
- SAM2LungSegmentor architecture
- FallbackEncoder for SAM2-free development
- SinusoidalPosEmbed

## [0.2.0] - 2025-01-20
### Added
- LUNA16 preprocessing pipeline
- LUNA16SliceDataset and LUNA16VolumeDataset
- Data augmentation pipeline
- Train/val/test split (72/14/14)

## [0.1.0] - 2025-01-08
### Added
- Initial repository structure
- Literature review notes (docs/literature_notes.md)
- LUNA16 data exploration notebook

================================================================================
SECTION 13: GITHUB-SPECIFIC REQUIREMENTS (for grad school application)
================================================================================

Based on research into what graduate admissions committees actually look for,
include the following in the repository:

13.1 GitHub Profile README compatibility
-----------------------------------------
The main README must look excellent when rendered on GitHub:
- All tables must render correctly in GitHub Markdown
- ASCII art must be monospaced-font compatible
- Badges must use shields.io format that renders as images on GitHub
- All code blocks must have language tags (```python, ```yaml, etc.)

13.2 .github/ directory
------------------------
Create .github/workflows/ci.yml:
A GitHub Actions workflow that:
- Triggers on push and pull_request to main
- Runs on ubuntu-latest with Python 3.10
- Steps: checkout, setup Python, pip install -r requirements.txt,
  run pytest tests/ -v --tb=short
- Shows test results in the Actions tab

Create .github/ISSUE_TEMPLATE/bug_report.md:
Standard bug report template.

13.3 releases/
--------------
Create a RELEASE_NOTES.md that describes what v1.0.0 contains
and links to the paper (placeholder arXiv link).
This signals to reviewers that this is a polished, versioned project.

13.4 setup.py
-------------
Make the project pip-installable:
from setuptools import setup, find_packages
with open("requirements.txt") as f:
    requirements = [...]

setup(
    name="sam2-lung-nodule-seg",
    version="1.0.0",
    author="Rahul Reddy Koulury",
    author_email="koulury2004@gmail.com",
    description="Uncertainty-aware lung nodule segmentation via SAM2 fine-tuning",
    packages=find_packages(),
    python_requires=">=3.10",
    install_requires=requirements,
    classifiers=[
        "Programming Language :: Python :: 3",
        "License :: OSI Approved :: MIT License",
        "Topic :: Scientific/Engineering :: Medical Science Apps.",
    ],
)

13.5 docs/literature_notes.md
------------------------------
A 300-400 word document listing 8-10 key papers that motivated the design.
Include papers on:
- SAM (Kirillov et al. 2023) and SAM2 (Ravi et al. 2024)
- MC Dropout (Gal & Ghahramani, 2016)
- LUNA16 challenge (Setio et al. 2017)
- Uncertainty in medical AI (Leibig et al., 2017)
- UNet for medical segmentation (Ronneberger et al. 2015)
- Temporal consistency in video segmentation

Format as a literature survey with a brief annotation for each paper explaining
why it motivated a specific design decision.

================================================================================
SECTION 14: COMMIT HISTORY STRATEGY
================================================================================

The commit history is visible on GitHub and signals whether this was real work
or a one-night project. Provide a git_commit_log.txt file containing a list
of 40-50 realistic commit messages with dates spanning January–June 2025.

Format each line as:
YYYY-MM-DD | commit message

Rules for commit messages:
- They should tell a development story
- Mix of feature additions, bug fixes, refactors, experiments
- Some should show failed experiments (e.g., "revert: 3D SAM2 too slow, back to 2D slice approach")
- Some should show iterative improvement
- Include some "fix: ..." commits (real projects have bugs)
- Include documentation updates
- Include performance numbers when relevant

Example range (expand to 45 commits):
2025-01-08 | initial commit: project structure and README skeleton
2025-01-09 | add: LUNA16 data download script and directory setup
2025-01-12 | feat: luna16_preprocessing.py — SimpleITK resampling pipeline
2025-01-15 | fix: HU windowing was normalizing before clipping, reversed
2025-01-18 | feat: create_nodule_mask with bounding box optimization
...
2025-06-14 | docs: update README with final clinical validation results
2025-06-15 | release: v1.0.0 — Slicer plugin + 150-study clinical validation

================================================================================
SECTION 15: WHAT TO ABSOLUTELY NOT DO
================================================================================

DO NOT:
- Leave any function as a stub with "pass" or "raise NotImplementedError"
- Use "TODO: implement" comments — this kills credibility instantly
- Have a requirements.txt with unpinned versions (use == not >=)
- Write a README that reads like a tutorial ("In this project, we will...")
- Use print() for logging in production code — use logging module
- Have a notebook that crashes on the first cell
- Forget to handle the case where SAM2 is not installed (graceful fallback)
- Write tests that only work with real LUNA16 data
- Leave placeholder text like "[Your Name]" or "REPLACE_ME" anywhere except
  download_luna16.sh where URLs genuinely need to be replaced

DO:
- Use logging.getLogger(__name__) everywhere
- Add type hints to all function signatures
- Write complete docstrings (Parameters, Returns, Notes sections)
- Make every __main__ block actually demonstrate something meaningful
- Ensure pytest tests/ -v passes with just pip install -r requirements.txt
- Comment non-obvious code choices (e.g., why we use bounding box in mask creation)
- Match metric values EXACTLY to what's stated in the CV: Dice=94.3%, κ=0.83, etc.

================================================================================
SECTION 16: OUTPUT FORMAT
================================================================================

Build all files sequentially. For each file:
1. State the filename as a header
2. Write the complete file contents
3. Do not truncate, abbreviate, or summarize

Start with: README.md → requirements.txt → setup.py → CHANGELOG.md → .gitignore
Then: data/ files → models/ files → training/ files → evaluation/ files
Then: slicer_plugin/ → notebooks/ → tests/ → scripts/ → configs/ → results/
Then: .github/ → docs/ → git_commit_log.txt

The total codebase should be approximately 4,000–6,000 lines of real code.
Every line should be something that a competent reviewer would not be embarrassed by.

This is the GitHub repository that accompanies a graduate school application
to NYU Abu Dhabi's MIDSAI program. It will be reviewed by professors who
specialize in clinical AI and NLP. Make it count.
================================================================================
END OF PROMPT
================================================================================